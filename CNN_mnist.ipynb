{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KdGSllOzdlo9"
   },
   "source": [
    "### Objective : For the given dataset Train a simple CNN classifier with 1 convolution layer, 1 max-pooling layer, 2 dense layers, and 1 dropout layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k-OIPpCtdlpA"
   },
   "source": [
    "#### Load the Libraries and  Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ETjaoHpdlpC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "train_data=pd.read_csv('mnist_train.csv')\n",
    "data_features=train_data.iloc[:,1:785]\n",
    "data_label=train_data.iloc[:,0]\n",
    "\n",
    "test_data=pd.read_csv('mnist_train.csv')\n",
    "X_test=test_data.iloc[:,1:785]\n",
    "Y_test=test_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PsXfVKZmdlpG"
   },
   "source": [
    "Here you will be required to train a very simple Convolutional Neural Network classifier with 1 convolution layer using the Keras deep learning library\n",
    "\n",
    "#### Split into a 80-20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NLwqm9C_dlpI"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_cv, Y_train, Y_cv=train_test_split(data_features, data_label, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S0-Q7HYddlpL"
   },
   "source": [
    "#### Processing Data\n",
    "After loading and splitting the data, You will now preprocess them by reshaping them into the shape the network expects and scaling them so that all values are in the [0, 1] interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XqbU-QkYdlpM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(48000, 28, 28, 1)\n",
      "(12000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train=X_train.to_numpy().reshape(48000,28,28,1)\n",
    "X_cv=X_cv.to_numpy().reshape(12000,28,28,1)\n",
    "X_test=X_test.to_numpy().reshape(60000,28,28,1)\n",
    "\n",
    "X_train=X_train.astype('float32')\n",
    "X_cv=X_cv.astype('float32')\n",
    "X_test=X_test.astype('float32')\n",
    "X_train/=255\n",
    "X_cv/=255\n",
    "X_test/=255\n",
    "\n",
    "digits=10\n",
    "Y_train=to_categorical(Y_train, digits)\n",
    "Y_cv=to_categorical(Y_cv, digits)\n",
    "Y_test=to_categorical(Y_test, digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rng4k3BodlpQ"
   },
   "source": [
    "#### CNN with 1 Convolutional Layer, 1 max-pooling layer, 2 dense layers, and 1 dropout layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pUSircWKdlpR"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "num_classes=10\n",
    "model=Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m0b1NRKzdlpV"
   },
   "source": [
    "\n",
    "##### Now when compiling the model, You must choose categorical_crossentropy as the loss function (which is relevent for multiclass, single-label classification problem) and Adam optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JxywAPHidlpW"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WUFGF9hSdlpb"
   },
   "source": [
    "#### Print your CNN Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3zN0JhCedlpc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               1384576   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,386,506\n",
      "Trainable params: 1,386,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nx6JvZCwdlpf"
   },
   "source": [
    "#### Training the Model\n",
    "\n",
    "You will train the model with batch size of 256 and 10 epochs on both training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wpm3-_pCdlpg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 31s 641us/step - loss: 1.6861 - accuracy: 0.5425 - val_loss: 0.8561 - val_accuracy: 0.8233\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 29s 602us/step - loss: 0.7601 - accuracy: 0.7806 - val_loss: 0.4784 - val_accuracy: 0.8783\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 29s 606us/step - loss: 0.5557 - accuracy: 0.8359 - val_loss: 0.3853 - val_accuracy: 0.8972\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 29s 602us/step - loss: 0.4731 - accuracy: 0.8602 - val_loss: 0.3362 - val_accuracy: 0.9056\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 29s 602us/step - loss: 0.4280 - accuracy: 0.8753 - val_loss: 0.3052 - val_accuracy: 0.9132\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 29s 607us/step - loss: 0.3927 - accuracy: 0.8847 - val_loss: 0.2829 - val_accuracy: 0.9184\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 31s 642us/step - loss: 0.3703 - accuracy: 0.8915 - val_loss: 0.2665 - val_accuracy: 0.9227\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 31s 636us/step - loss: 0.3503 - accuracy: 0.8977 - val_loss: 0.2526 - val_accuracy: 0.9256\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 30s 634us/step - loss: 0.3365 - accuracy: 0.9017 - val_loss: 0.2421 - val_accuracy: 0.9292\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 30s 634us/step - loss: 0.3170 - accuracy: 0.9079 - val_loss: 0.2310 - val_accuracy: 0.9323\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, Y_train, batch_size=256, epochs=10, validation_data=(X_cv, Y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FNoMxkP3dlpl"
   },
   "source": [
    "#### Here you will Print your Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0aqzID1jdlpm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 9s 195us/step\n",
      "accuracy =93.36249828338623\n"
     ]
    }
   ],
   "source": [
    "acc=model.evaluate(X_train, Y_train)\n",
    "print(\"accuracy =%s\"%(acc[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rQFobH1hdlpp"
   },
   "source": [
    "#### Classification Report\n",
    "\n",
    "Summarize the performance of the classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NObTVDwydlpq"
   },
   "outputs": [],
   "source": [
    "Y_pred=model.predict_classes(X_test, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y4UwRJgQdlpt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      5923\n",
      "           1       0.96      0.97      0.97      6742\n",
      "           2       0.92      0.93      0.92      5958\n",
      "           3       0.92      0.89      0.91      6131\n",
      "           4       0.93      0.94      0.93      5842\n",
      "           5       0.93      0.89      0.91      5421\n",
      "           6       0.94      0.97      0.96      5918\n",
      "           7       0.95      0.94      0.94      6265\n",
      "           8       0.91      0.91      0.91      5851\n",
      "           9       0.90      0.92      0.91      5949\n",
      "\n",
      "    accuracy                           0.93     60000\n",
      "   macro avg       0.93      0.93      0.93     60000\n",
      "weighted avg       0.93      0.93      0.93     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#Converting y_test to acceptable format for the report\n",
    "\n",
    "Y_test=Y_test.argmax(axis=-1)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Mini_Project_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
