{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random\n",
    "from random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a network\n",
    "# a network is represented as a list of dictionaries\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    network=list()\n",
    "    hidden_layer=[{'weights':[random() for i in range(n_inputs+1)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer)\n",
    "    outer_layer=[{'weights':[random() for i in range(n_hidden+1)]} for i in range(n_outputs)]\n",
    "    network.append(outer_layer)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}]\n",
      "\n",
      "[{'weights': [0.2550690257394217, 0.49543508709194095]}, {'weights': [0.4494910647887381, 0.651592972722763]}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test a network creation\n",
    "seed(1)\n",
    "network=initialize_network(2,1,2)\n",
    "for layer in network:\n",
    "    print(layer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "# Activation function: \n",
    "\n",
    "def linear(weights, inputs):\n",
    "    linear=weights[-1] # Store the last weight as bias\n",
    "    for i in range(len(weights)-1):\n",
    "        linear += weights[i]*inputs[i]\n",
    "    return linear\n",
    "\n",
    "def activation(x):\n",
    "    return 1.0/(1.0+ np.exp(-x))\n",
    "\n",
    "def forward_propagation(network, row):\n",
    "    inputs=row\n",
    "    for layer in network:\n",
    "        new_inputs=[]\n",
    "        for neuron in layer:\n",
    "            linearComb=linear(neuron['weights'], row)\n",
    "            neuron['output']=activation(linearComb)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs=new_inputs\n",
    "    return inputs         \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6792885329144388, 0.7504631664645315]\n"
     ]
    }
   ],
   "source": [
    "# Test the forward prop\n",
    "network = [[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
    "[{'weights': [0.2550690257394217, 0.49543508709194095]}, {'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
    "row=[1,0, None]\n",
    "output=forward_propagation(network, row)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_derivative(x):\n",
    "    return x * (1.0-x)\n",
    "def back_propagation(network, expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "    \n",
    "        layer=network[i]\n",
    "        errors=list()\n",
    "        # if i is not the last layer do\n",
    "        if i != len(network)-1:\n",
    "            for j in range(len(layer)):\n",
    "                error=0.0\n",
    "                for neuron in network[i+1]:\n",
    "                    error+=(neuron['weights'][j] * neuron['delta']) *activation_derivative(layer[j]['output'])\n",
    "                    errors.append(error)\n",
    "        else:# if i is the last layer\n",
    "            for j in range(len(layer)):\n",
    "                neuron=layer[j]\n",
    "                errors.append(expected[j]-neuron['output'])\n",
    "        for j in range(len(layer)):\n",
    "            \n",
    "            neuron=layer[j]\n",
    "            neuron['delta']=errors[j]*activation_derivative(neuron['output'])\n",
    "        \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'delta': -0.0015771887491200093}]\n",
      "[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095], 'delta': -0.14619064683582808}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763], 'delta': 0.0771723774346327}]\n"
     ]
    }
   ],
   "source": [
    "network = [[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
    "[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095]}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
    "expected = [0, 1]\n",
    "back_propagation(network, expected)\n",
    "for layer in network:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(network, row, eta):\n",
    "    for i in range(len(network)):\n",
    "        inputs=row[:-1]\n",
    "        if i!=0:\n",
    "            inputs=[neuron['output'] for neuron in network[i-1]]\n",
    "        for neuron in network[i]:\n",
    "            for j in range(len(inputs)):\n",
    "                neuron['weights'][j]+=eta*neuron['delta']*inputs[j]\n",
    "            neuron['weights'][-1] += eta * neuron['delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            outputs = forward_propagation(network, row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            expected[row[-1]] = 1\n",
    "            sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "            back_propagation(network, expected)\n",
    "            update_weights(network, row, l_rate)\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.500, error=7.269\n",
      ">epoch=1, lrate=0.500, error=6.077\n",
      ">epoch=2, lrate=0.500, error=6.025\n",
      ">epoch=3, lrate=0.500, error=5.951\n",
      ">epoch=4, lrate=0.500, error=5.882\n",
      ">epoch=5, lrate=0.500, error=5.824\n",
      ">epoch=6, lrate=0.500, error=5.782\n",
      ">epoch=7, lrate=0.500, error=5.739\n",
      ">epoch=8, lrate=0.500, error=5.697\n",
      ">epoch=9, lrate=0.500, error=5.657\n",
      ">epoch=10, lrate=0.500, error=5.619\n",
      ">epoch=11, lrate=0.500, error=5.579\n",
      ">epoch=12, lrate=0.500, error=5.533\n",
      ">epoch=13, lrate=0.500, error=5.474\n",
      ">epoch=14, lrate=0.500, error=5.396\n",
      ">epoch=15, lrate=0.500, error=5.291\n",
      ">epoch=16, lrate=0.500, error=5.155\n",
      ">epoch=17, lrate=0.500, error=4.992\n",
      ">epoch=18, lrate=0.500, error=4.814\n",
      ">epoch=19, lrate=0.500, error=4.634\n",
      "[{'weights': [0.7665992372349709, 0.0653135178788911, 0.015889783956363212], 'output': 0.9978232428381898, 'delta': 6.39943721605866e-08}, {'weights': [0.832517249353776, 0.4284676877063701, 0.7604714186299393], 'output': 0.99982530805101, 'delta': 5.6778207567042455e-09}]\n",
      "[{'weights': [-0.4329594729492105, 0.30797961519729267, 0.669802015784139], 'output': 0.20196419203559468, 'delta': -0.032551509412155816}, {'weights': [0.05389061339032675, 0.26617334495734857, 0.07305564437179311], 'output': 0.7604250877575452, 'delta': 0.04364546371358374}]\n"
     ]
    }
   ],
   "source": [
    "dataset = [[2.7810836,2.550537003,0],\n",
    "           [1.465489372,2.362125076,0],\n",
    "           [3.396561688,4.400293529,0],           \n",
    "           [1.38807019,1.850220317,0],\n",
    "           [3.06407232,3.005305973,0],\n",
    "           [7.627531214,2.759262235,1],\n",
    "           [5.332441248,2.088626775,1],\n",
    "           [6.922596716,1.77106367,1],\n",
    "           [8.675418651,-0.242068655,1],\n",
    "           [7.673756466,3.508563011,1]]\n",
    "n_inputs = len(dataset[0]) - 1\n",
    "n_outputs = len(set([row[-1] for row in dataset]))\n",
    "network = initialize_network(n_inputs, 2, n_outputs)\n",
    "train_network(network, dataset, 0.5, 20, n_outputs)\n",
    "for layer in network:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
