{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The code in this file trains the an efficientnet model on the train data","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:36:50.682855Z","iopub.execute_input":"2021-06-17T12:36:50.683287Z","iopub.status.idle":"2021-06-17T12:36:59.575482Z","shell.execute_reply.started":"2021-06-17T12:36:50.683199Z","shell.execute_reply":"2021-06-17T12:36:59.574452Z"}}},{"cell_type":"code","source":"# Install the efficientnet model\n!pip install efficientnet -q","metadata":{"execution":{"iopub.status.busy":"2021-06-21T16:36:51.767988Z","iopub.execute_input":"2021-06-21T16:36:51.768615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nimport efficientnet.tfkeras as efn\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom sklearn.model_selection import KFold\nimport re\nimport tensorflow_addons as tfa","metadata":{"execution":{"iopub.status.busy":"2021-06-21T16:36:41.895658Z","iopub.execute_input":"2021-06-21T16:36:41.896110Z","iopub.status.idle":"2021-06-21T16:36:41.976906Z","shell.execute_reply.started":"2021-06-21T16:36:41.896023Z","shell.execute_reply":"2021-06-21T16:36:41.975624Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-604d72c979df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mefficientnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mefn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkaggle_datasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKaggleDatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'efficientnet'"],"ename":"ModuleNotFoundError","evalue":"No module named 'efficientnet'","output_type":"error"}]},{"cell_type":"code","source":"# Initialize the TPU\ndef select_tpu():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    \n    return strategy\nselect_tpu()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T16:36:48.005214Z","iopub.execute_input":"2021-06-21T16:36:48.005877Z","iopub.status.idle":"2021-06-21T16:36:48.032686Z","shell.execute_reply.started":"2021-06-21T16:36:48.005733Z","shell.execute_reply":"2021-06-21T16:36:48.031164Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-3c167899de6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mselect_tpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-2-3c167899de6a>\u001b[0m in \u001b[0;36mselect_tpu\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_tpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_connect_to_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_tpu_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"],"ename":"NameError","evalue":"name 'tf' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# Function to read the jpeg images, reshape them, and convert them into float\ndef decode_image(image_data):\n        \n    image = tf.image.decode_jpeg(image_data, channels=3)\n    \n    image = tf.reshape(image, [256, 256, 3])\n    image = tf.cast(image, tf.float32) / 255    \n    return image\n","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:37:12.312828Z","iopub.execute_input":"2021-06-17T12:37:12.313116Z","iopub.status.idle":"2021-06-17T12:37:12.318719Z","shell.execute_reply.started":"2021-06-17T12:37:12.313085Z","shell.execute_reply":"2021-06-17T12:37:12.317512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mapping of the tfrecord fields to corresponding datatype\nfeature_map = {\n    'image':tf.io.FixedLenFeature([], tf.string),\n    'target': tf.io.FixedLenFeature([], tf.int64),\n    'StudyInstanceUID': tf.io.FixedLenFeature([], tf.string),\n    'only_label': tf.io.FixedLenFeature([], tf.int64),\n    'Negative for Pneumonia': tf.io.FixedLenFeature([], tf.int64),\n    'Typical Appearance': tf.io.FixedLenFeature([], tf.int64),\n    'Indeterminate Appearance': tf.io.FixedLenFeature([], tf.int64),\n    'Atypical Appearance': tf.io.FixedLenFeature([], tf.int64),\n    'img_path':tf.io.FixedLenFeature([], tf.string),\n    'image_id':tf.io.FixedLenFeature([], tf.string),\n    'dim0':tf.io.FixedLenFeature([], tf.int64),\n    'dim1':tf.io.FixedLenFeature([], tf.int64),\n    'xmin':tf.io.FixedLenFeature([], tf.float32),\n    'ymin':tf.io.FixedLenFeature([], tf.float32),\n    'xmax':tf.io.FixedLenFeature([], tf.float32),\n    'ymax':tf.io.FixedLenFeature([], tf.float32)\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:37:12.320436Z","iopub.execute_input":"2021-06-17T12:37:12.320959Z","iopub.status.idle":"2021-06-17T12:37:12.332697Z","shell.execute_reply.started":"2021-06-17T12:37:12.320915Z","shell.execute_reply":"2021-06-17T12:37:12.331202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to read the tfrecords\ndef read_tfrecord(example, labeled=True):\n    '''\n        example: single tfrecord\n        labeled: indicated whether the data is labeled or unlabeled\n        \n        returns:\n            image: An image tensor\n    '''\n    \n    # Parse an record with the help of the feature map\n    example = tf.io.parse_single_example(example, feature_map)  \n    \n    # Decode the image from the record\n    image = decode_image(example['image'])  \n    \n    # If the data is labeled, return the multiple labels along with\n    # the image data\n    if labeled:\n        label = tf.one_hot(example['target'], 4)\n        \n    else:\n        return image\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:37:12.334456Z","iopub.execute_input":"2021-06-17T12:37:12.33505Z","iopub.status.idle":"2021-06-17T12:37:12.349851Z","shell.execute_reply.started":"2021-06-17T12:37:12.335012Z","shell.execute_reply":"2021-06-17T12:37:12.348587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function that returns a tf dataset from the list of files\ndef get_dataset(files,batch_size=10,shuffle = False, repeat = False, labeled=True):\n    \n    AUTO     = tf.data.experimental.AUTOTUNE\n    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n    ds = ds.cache()\n    \n    if repeat:\n        ds = ds.repeat()\n    \n    if shuffle: \n        ds = ds.shuffle(1024*8)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n    \n    \n    if labeled:\n        ds = ds.map(lambda example:read_tfrecord(example), num_parallel_calls=AUTO)\n    else:\n        ds = ds.map(lambda example: read_tfrecord(example, labeled=False), \n                    num_parallel_calls=AUTO)  \n      \n    #ds = ds.map(lambda img, imgname_or_label: (decode_image(img),imgname_or_label),num_parallel_calls=AUTO)\n    \n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(AUTO)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:37:12.351716Z","iopub.execute_input":"2021-06-17T12:37:12.352218Z","iopub.status.idle":"2021-06-17T12:37:12.363204Z","shell.execute_reply.started":"2021-06-17T12:37:12.35218Z","shell.execute_reply":"2021-06-17T12:37:12.361784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')\nstudy_labels=list(data.columns[1:5])\nstudy_labels","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:37:12.367302Z","iopub.execute_input":"2021-06-17T12:37:12.367735Z","iopub.status.idle":"2021-06-17T12:37:12.406312Z","shell.execute_reply.started":"2021-06-17T12:37:12.367701Z","shell.execute_reply":"2021-06-17T12:37:12.405289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function that returns an efficientnet model for the transfer learning\ndef get_model():\n    \n    inp = tf.keras.layers.Input(shape=(256,256,3))\n    base = efn.EfficientNetB6(input_shape=(256,256,3),weights='imagenet',include_top=False)\n    x = base(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(64, activation = 'relu')(x)\n    x = tf.keras.layers.Dense(4,activation='softmax')(x)\n    model = tf.keras.Model(inputs=inp,outputs=x)\n    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.01)\n    auc = tf.keras.metrics.AUC(curve='ROC',\n                               multi_label=True)\n    acc = tf.keras.metrics.CategoricalAccuracy()\n    f1  = tfa.metrics.F1Score(num_classes=4,average='macro',threshold=None)\n    model.compile(optimizer=opt,loss=loss,metrics=[auc, acc, f1])\n    return model\n    \n       \n    \n    \n    \n   ","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:37:12.407832Z","iopub.execute_input":"2021-06-17T12:37:12.408141Z","iopub.status.idle":"2021-06-17T12:37:12.417921Z","shell.execute_reply.started":"2021-06-17T12:37:12.40811Z","shell.execute_reply":"2021-06-17T12:37:12.416597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:37:12.4194Z","iopub.execute_input":"2021-06-17T12:37:12.419831Z","iopub.status.idle":"2021-06-17T12:37:12.619698Z","shell.execute_reply.started":"2021-06-17T12:37:12.419788Z","shell.execute_reply":"2021-06-17T12:37:12.618747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the tfrec files\nGCS_PATH=KaggleDatasets().get_gcs_path('tfrecssiim')\ntrain_files=np.sort(np.array(tf.io.gfile.glob(GCS_PATH+'/train*.tfrec')))\ntest_files=np.sort(np.array(tf.io.gfile.glob(GCS_PATH+'/test*.tfrec')))","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:37:12.620899Z","iopub.execute_input":"2021-06-17T12:37:12.621188Z","iopub.status.idle":"2021-06-17T12:37:14.406503Z","shell.execute_reply.started":"2021-06-17T12:37:12.62116Z","shell.execute_reply":"2021-06-17T12:37:14.405472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count thefiles in the tfrecord\ndef get_file_count(ds):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in ds]\n    \n    return np.sum(n)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:37:14.409737Z","iopub.execute_input":"2021-06-17T12:37:14.410103Z","iopub.status.idle":"2021-06-17T12:37:14.415215Z","shell.execute_reply.started":"2021-06-17T12:37:14.410069Z","shell.execute_reply":"2021-06-17T12:37:14.414077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FOLDS=5\nSEED=42\nEPOCHS=20\nBATCH_SIZE=16\n","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:37:14.416709Z","iopub.execute_input":"2021-06-17T12:37:14.417297Z","iopub.status.idle":"2021-06-17T12:37:14.429316Z","shell.execute_reply.started":"2021-06-17T12:37:14.417253Z","shell.execute_reply":"2021-06-17T12:37:14.427928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_lr_callback(batch_size=8):\n    lr_start   = 0.000005\n    lr_max     = 0.00000125 * 8 * batch_size\n    lr_min     = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n            \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max\n            \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n            \n        return lr\n   \n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback\n\n#_=get_lr_callback(BATCH_SIZE[0], plot=True )","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:37:14.4313Z","iopub.execute_input":"2021-06-17T12:37:14.432912Z","iopub.status.idle":"2021-06-17T12:37:14.445193Z","shell.execute_reply.started":"2021-06-17T12:37:14.432841Z","shell.execute_reply":"2021-06-17T12:37:14.444039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# \n\nskf=KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\npreds=np.zeros((get_file_count(test_files),1))\nfiles_train=[]\nfiles_val=[]\noof_pred=[]\noof_tar=[]\nfor fold, (tridx, validx) in enumerate(skf.split(np.arange(15))):\n    print(f'Running fold {fold}')\n    files_train=tf.io.gfile.glob([GCS_PATH + '/train%.2i*.tfrec'%i for i in tridx])\n    files_val=tf.io.gfile.glob([GCS_PATH+'/train%.2i*.tfrec'% i for i in validx])\n    \n    with select_tpu().scope():\n        model=get_model()\n        \n        \n        # save the best model in each fold\n        cb=tf.keras.callbacks.ModelCheckpoint('fold-%i.h5'%fold, monitor='val_loss', verbose=0, save_best_only=True, \n                                             save_weights_only=True, mode='min', save_freq='epoch')\n        # Train the model\n        steps_per_epoch=get_file_count(train_files)/BATCH_SIZE//8\n        print(steps_per_epoch)\n           \n        # Create the train and val datasets\n        tr_ds=get_dataset(files_train,BATCH_SIZE, shuffle = True, repeat = True)\n        val_ds=get_dataset(files_val,BATCH_SIZE, shuffle = False, repeat = False)\n        \n        # Train the model\n        history=model.fit(tr_ds, epochs=EPOCHS, callbacks=[cb,get_lr_callback(BATCH_SIZE)],steps_per_epoch=steps_per_epoch,validation_data=val_ds, verbose=1)\n        \n        \n        \n    \n        ","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:37:14.446757Z","iopub.execute_input":"2021-06-17T12:37:14.447181Z","iopub.status.idle":"2021-06-17T12:37:26.709737Z","shell.execute_reply.started":"2021-06-17T12:37:14.44714Z","shell.execute_reply":"2021-06-17T12:37:26.705243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:37:26.710967Z","iopub.status.idle":"2021-06-17T12:37:26.711486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}